Generative AI use cases, project lifecycle, and model pre-training

Learning Objectives

Discuss model pre-training and the value of continued pre-training vs fine-tuning

Define the terms Generative AI, large language models, prompt, and describe the transformer architecture that powers LLMs

Describe the steps in a typical LLM-based, generative AI model lifecycle and discuss the constraining factors that drive decisions at each step of model lifecycle

Discuss computational challenges during model pre-training and determine how to efficiently reduce memory footprint

Define the term scaling law and describe the laws that have been discovered for LLMs related to training dataset size, compute budget, inference requirements, and other factors.
